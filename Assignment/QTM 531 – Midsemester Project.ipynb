{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QTM 531 â€“ Midsemester Project\n",
    "## Ao Lyu (Lorna)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project I will create and analyze a bage dataset in Amazon via web scraping. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">\n",
    "\n",
    "Import packages for data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manage datasets\n",
    "import pandas as pd\n",
    "\n",
    "# Work with time data\n",
    "import time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">\n",
    "\n",
    "Import packages for HTML processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conduct HTTP requests\n",
    "import requests\n",
    "\n",
    "# Construct tree structure of HTML data\n",
    "import html5lib\n",
    "\n",
    "# Parse HTML data obtained from scraping\n",
    "from bs4 import BeautifulSoup as soup "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">\n",
    "\n",
    "Import packages for interactive <br>\n",
    "website navigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import webdriver for chrome\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# Automate navigating within browser (SELENIUM)\n",
    "#------ Key: Manage keys\n",
    "#------ Select: Obtain features from website\n",
    "#------ WebDriverWait: Add wait times implicitly\n",
    "#------ By: Use common information locator strategies\n",
    "#------ EC and Options: Browser configuration\n",
    "#------ remote.command: Check whether browser is active\n",
    "\n",
    "from selenium import webdriver #to automate the navigating within the browser\n",
    "from selenium.webdriver.common.keys    import Keys\n",
    "from selenium.webdriver.support.ui     import Select\n",
    "from selenium.webdriver.support.ui     import WebDriverWait \n",
    "from selenium.webdriver.common.by      import By\n",
    "from selenium.webdriver.support        import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options #to use properties of the chrome webbrowser\n",
    "from selenium.webdriver.remote.command import Command # Use to check whether the web driver is active\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from datetime import date\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "import subprocess\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:darkblue\"> I. Running Chrome from Python </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://www.urbanoutfitters.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4d/z4q5k4qd0bgclyqnxbr4wkwr0000gn/T/ipykernel_74825/2782179360.py:5: DeprecationWarning: headless property is deprecated, instead use add_argument('--headless') or add_argument('--headless=new')\n",
      "  options.headless = False\n",
      "/var/folders/4d/z4q5k4qd0bgclyqnxbr4wkwr0000gn/T/ipykernel_74825/2782179360.py:7: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install(), options=options)\n"
     ]
    }
   ],
   "source": [
    "options = Options()\n",
    "\n",
    "# True hides the navigating of the browser by the scraper,\n",
    "# False shows you the tab/window opening and stuff getting clicked\n",
    "options.headless = False \n",
    "\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install(), options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(base_url)\n",
    "html_content = response.text\n",
    "soup = BeautifulSoup(html_content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4d/z4q5k4qd0bgclyqnxbr4wkwr0000gn/T/ipykernel_74825/2051482228.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install())\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "driver.get(\"https://www.urbanoutfitters.com/dresses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "list_forms = driver.find_elements(By.CLASS_NAME, 'form-control')\n",
    "len(list_forms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# Setup Selenium WebDriver\n",
    "options = webdriver.ChromeOptions()\n",
    "# Optional: run in headless mode\n",
    "# options.add_argument('--headless')\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "# Navigate to the website\n",
    "driver.get('https://www.urbanoutfitters.com/dresses')\n",
    "\n",
    "# Wait for the page to load (consider explicit waits for specific elements)\n",
    "driver.implicitly_wait(10)\n",
    "\n",
    "# Now you can extract the page source\n",
    "page_source = driver.page_source\n",
    "\n",
    "# Proceed with BeautifulSoup or continue using Selenium to interact with the page\n",
    "# soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "# Remember to close the driver after your scraping job is done\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$79.00\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Your HTML snippet\n",
    "html_snippet = '''\n",
    "<span aria-label=\"Original price: $79.00\" class=\"c-pwa-product-price__current s-pwa-product-price__current\">$79.00</span>\n",
    "'''\n",
    "\n",
    "# Parse the HTML with BeautifulSoup\n",
    "soup = BeautifulSoup(html_snippet, 'html.parser')\n",
    "\n",
    "# Find the span element with the class 'c-pwa-product-price__current'\n",
    "# and get its text content, which is the price\n",
    "price = soup.find('span', class_='c-pwa-product-price__current').text\n",
    "\n",
    "print(price)  # This should print \"$79.00\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dresses = soup.find_all('div', class_='dress-item')  # Example class name\n",
    "for dress in dresses:\n",
    "    price_span= soup.find('span', class_='c-pwa-product-price__current s-pwa-product-price__current')  \n",
    "    price = dress.find('span', class_='price').text  # Example class name\n",
    "    # Extract other details similarly\n",
    "    print(f'Name: {name}, Price: {price}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Name': [], 'Price': []}  # Add more fields as needed\n",
    "for dress in dresses:\n",
    "    data['Name'].append(dress.find('h2', class_='name').text)\n",
    "    data['Price'].append(dress.find('span', class_='price').text)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df.describe())  # Basic statistics\n",
    "df.to_csv('dresses.csv', index=False)  # Save to CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'store_response'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstore_response\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StoreResponseError, get_store_response\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscraper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m scrape_store\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'store_response'"
     ]
    }
   ],
   "source": [
    "from store_response import StoreResponseError, get_store_response\n",
    "from scraper import scrape_store\n",
    "\n",
    "def main():\n",
    "    store_url = input(\"https://www.urbanoutfitters.com/womens-clothing\")\n",
    "    try:\n",
    "        store_response = get_store_response(store_url)\n",
    "        if store_response:\n",
    "            scrape_store(store_response, store_url)\n",
    "    except StoreResponseError as e:\n",
    "        print(e)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'message': 'Unauthorized'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from pprint import pprint\n",
    "\n",
    "# Structure payload.\n",
    "payload = {\n",
    "    'source': 'universal_ecommerce',\n",
    "    'url': 'https://www.etsy.com/listing/524233279/tiny-silver-forget-me-not-earrings',\n",
    "    'geo_location': 'United States',\n",
    "    'parse': True,\n",
    "}\n",
    "\n",
    "# Get response.\n",
    "response = requests.request(\n",
    "    'POST',\n",
    "    'https://realtime.oxylabs.io/v1/queries',\n",
    "    auth=('user', 'pass1'),\n",
    "    json=payload,\n",
    ")\n",
    "\n",
    "# Instead of response with job status and results url, this will return the\n",
    "# JSON response with the result.\n",
    "pprint(response.json())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
